{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:red'> NETFLIX </span> \n",
    "## EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Spark and Netflix Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting spark session\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Netflix').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling netflix data set as df\n",
    "df = spark.read.csv('netflix_titles.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inspecting schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns groups based profiling to better understand our data\n",
    "\n",
    "we will examine columns which we can group by for further analysis while acknowledging columns which will need more complex tranformation in order to group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of columns show_id,type,title,director,cast,rating,listed_in,description\n",
      "+-------+----------------+-------+---------------------------------+--------------------+--------------------+-----------------+---------------+--------------------+\n",
      "|summary|         show_id|   type|                            title|            director|                cast|           rating|      listed_in|         description|\n",
      "+-------+----------------+-------+---------------------------------+--------------------+--------------------+-----------------+---------------+--------------------+\n",
      "|  count|            7788|   7788|                             7787|                5398|                7070|             7780|           7786|                7786|\n",
      "|   mean|            null|   null|               1084.7272727272727|                null|                null|          2015.75|           null|  2014.6666666666667|\n",
      "| stddev|            null|   null|               1096.7795668145072|                null|                null|6.701989754294367|           null|   4.509249752822894|\n",
      "|    min|Flying Fortress\"|  Movie|             \"Behind \"\"The Cov...|\"Sam \"\"Blitz\"\" Ba...|\"Black Deniro, By...|    Adriane Lenox| Eden Marryshow|      Alicia Sánchez|\n",
      "|    25%|            null|   null|                             46.0|                null|                null|           2006.0|           null|              2010.0|\n",
      "|    50%|            null|   null|                            706.0|                null|                null|           2017.0|           null|              2015.0|\n",
      "|    75%|            null|   null|                           1983.0|                null|                null|           2019.0|           null|              2019.0|\n",
      "|    max|            s999|TV Show|최강전사 미니특공대 : 영웅의 탄생|        Şenol Sönmez|Ṣọpẹ́ Dìrísù, Wun...|               UR|  United States|Zoe Walker leaves...|\n",
      "+-------+----------------+-------+---------------------------------+--------------------+--------------------+-----------------+---------------+--------------------+\n",
      "\n",
      "Checking for nulls on columns show_id,type,title,director,cast,rating,listed_in,description:\n",
      "+-------+----+-----+--------+----+------+---------+-----------+\n",
      "|show_id|type|title|director|cast|rating|listed_in|description|\n",
      "+-------+----+-----+--------+----+------+---------+-----------+\n",
      "|      0|   0|    1|    2390| 718|     8|        2|          2|\n",
      "+-------+----+-----+--------+----+------+---------+-----------+\n",
      "\n",
      "Checking amount of distinct values in columns show_id,type,title,director,cast,rating,listed_in,description:\n",
      "+----+-----+--------+----+------+---------+-----------+\n",
      "|type|title|director|cast|rating|listed_in|description|\n",
      "+----+-----+--------+----+------+---------+-----------+\n",
      "|   2| 7787|    4049|6832|    29|      505|       7767|\n",
      "+----+-----+--------+----+------+---------+-----------+\n",
      "\n",
      "Most and least frequent occurrences for type,director,cast,rating columns:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| leastFreqtype | mostFreqtype | leastFreqdirector | mostFreqdirector |\n",
       "|----|----|----|----|\n",
       "| TV Show (2410 occurrences) | Movie (5378 occurrences) | Gaby Dellal (1 occurrences) | None (2390 occurrences) |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| leastFreqcast | mostFreqcast | leastFreqrating | mostFreqrating |\n",
       "|----|----|----|----|\n",
       "| Tedd Chan, Stella Chung, Henley Hii, Lawrence Koh, Tommy Kuan, Josh Lai, Mark Lee, Susan Leong, Benjamin Lim (1 occurrences) | None (718 occurrences) | November 1, 2020 (1 occurrences) | TV-MA (2854 occurrences) |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first\n",
    "\n",
    "print (\"Summary of columns show_id,type,title,director,cast,rating,listed_in,description\")\n",
    "df.select(\"show_id\",'type','title','director','cast','rating','listed_in','description').summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns show_id,type,title,director,cast,rating,listed_in,description:\")\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"show_id\",'type','title','director','cast','rating','listed_in','description']]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns show_id,type,title,director,cast,rating,listed_in,description:\")\n",
    "df.select([countDistinct(c).alias(c) for c in ['type','title','director','cast','rating','listed_in','description']]).show()\n",
    "\n",
    "print (\"Most and least frequent occurrences for type,director,cast,rating columns:\")\n",
    "typeDF = df.groupBy(\"type\").agg(count(lit(1)).alias(\"Total\"))\n",
    "directorDF    = df.groupBy(\"director\").agg(count(lit(1)).alias(\"Total\"))\n",
    "castDF      = df.groupBy(\"cast\").agg(count(lit(1)).alias(\"Total\"))\n",
    "ratingDF      = df.groupBy(\"rating\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "leastFreqtype    = typeDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqtype     = typeDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqdirector       = directorDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqdirector        = directorDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqcast         = castDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqcast          = castDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqrating         = ratingDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqrating          = ratingDF.orderBy(col(\"Total\").desc()).first()\n",
    "\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqtype\", \"mostFreqtype\", \"leastFreqdirector\", \"mostFreqdirector\", \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqtype[\"type\"], leastFreqtype[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqtype[\"type\"], mostFreqtype[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqdirector[\"director\"], leastFreqdirector[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqdirector[\"director\"], mostFreqdirector[\"Total\"]))))\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqcast\", \"mostFreqcast\", \"leastFreqrating\", \"mostFreqrating\", \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqcast[\"cast\"], leastFreqcast[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqcast[\"cast\"], mostFreqcast[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqrating[\"rating\"], leastFreqrating[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqrating[\"rating\"], mostFreqrating[\"Total\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distribution of TV Shows and Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content on Netflix is classified mainly between TV Shows and Movies with **31%** being TV shows and **69%** being Movies.\n",
    "<br>\n",
    "<br>\n",
    "Netflix relies more on externally productions on top of Netflix Originals to build their Movie library where as it focuses more on Netflix Originals for its TV show library thus explaining the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         type|count|\n",
      "+-------------+-----+\n",
      "|         null|    1|\n",
      "|      TV Show| 2410|\n",
      "|        Movie| 5377|\n",
      "|William Wyler|    1|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#content type in Netlfix is primarly distributed into two types - tv shows and movies\n",
    "by_type = df.groupBy('type').count()\n",
    "by_type.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on examining William Wyler we observe it is actually a Movie and replace the type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('type',regexp_replace('type','William Wyler','Movie'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping null value by defining a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(thresh=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   type|count|\n",
      "+-------+-----+\n",
      "|TV Show| 2410|\n",
      "|  Movie| 5378|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "by_type = df.groupBy('type').count()\n",
    "by_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+\n",
      "|   type|count|share %|\n",
      "+-------+-----+-------+\n",
      "|TV Show| 2410|  30.95|\n",
      "|  Movie| 5378|  69.05|\n",
      "+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#total sum of counts = 7787\n",
    "sum_of_counts = by_type.select(sum(by_type['count'])).collect()[0][0]\n",
    "\n",
    "#share of total type\n",
    "by_type.withColumn('share %',round(by_type['count']/sum_of_counts*100,2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** **Total Content Added Yearly**\n",
    "<br>\n",
    "<br>\n",
    "As Netflix grows more popular year after year, we see an increase in content added growing **75%** from 2017 to 2019. The dip in 2020 **(6%)** is most probably because of the halt in production due to the pandemic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting year from column date_added\n",
    "df_mod = df.withColumn('added_year',split(col('date_added'),',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|added_year|count|\n",
      "+----------+-----+\n",
      "|      2017| 1223|\n",
      "|      2018| 1683|\n",
      "|      2019| 2151|\n",
      "|      2020| 2003|\n",
      "|      2021|  115|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating temporary table for sql\n",
    "df_mod.createOrReplaceTempView('df_mod')\n",
    "\n",
    "spark.sql('SELECT added_year,COUNT(*) as count FROM df_mod \\\n",
    "           WHERE added_year = 2017 OR added_year = 2018 OR added_year = 2019 OR added_year = 2020 or added_year = 2021 \\\n",
    "           GROUP BY added_year \\\n",
    "           ORDER BY added_year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% increase from 2017 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.8789860997547"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % increase from 2017 to 2019\n",
    "(2151/1223-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% drop from 2019 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.880520688052072"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % drop from 2019 to 2020\n",
    "(2003/2151-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** **TV Show Content Added Yearly**\n",
    "<br>\n",
    "<br>\n",
    "increase of **92%** from 2017 to 2020\n",
    "<br>\n",
    "increase of **6%** from 2019 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+\n",
      "|   type|added_year|count|\n",
      "+-------+----------+-----+\n",
      "|TV Show|      2017|  361|\n",
      "|TV Show|      2018|  430|\n",
      "|TV Show|      2019|  655|\n",
      "|TV Show|      2020|  696|\n",
      "|TV Show|      2021|   29|\n",
      "+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtering for tv_shows\n",
    "df_mod_tv_show = df_mod.filter(df['type']=='TV Show')\n",
    "\n",
    "df_mod_tv_show.createOrReplaceTempView('df_mod_tv_show')\n",
    "\n",
    "spark.sql('SELECT type,added_year,COUNT(*) as count FROM df_mod_tv_show \\\n",
    "           WHERE added_year = 2017 OR added_year = 2018 OR added_year = 2019 OR added_year = 2020 or added_year = 2021 \\\n",
    "           GROUP BY type,added_year ORDER BY added_year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% increase from 2017 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.797783933518"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % increase from 2017 to 2020\n",
    "((696/361)-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% increase from 2019 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.259541984732819"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % increase from 2019 to 2020\n",
    "((696/655)-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** **Movie Content Added Yearly**\n",
    "<br>\n",
    "<br>\n",
    "increase of **52%** from 2017 to 2020\n",
    "<br>\n",
    "drop of **12%** from 2019 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "| type|added_year|count|\n",
      "+-----+----------+-----+\n",
      "|Movie|      2017|  862|\n",
      "|Movie|      2018| 1253|\n",
      "|Movie|      2019| 1496|\n",
      "|Movie|      2020| 1307|\n",
      "|Movie|      2021|   86|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtering for movies\n",
    "df_mod_movie = df_mod.filter(df['type']=='Movie')\n",
    "\n",
    "df_mod_movie.createOrReplaceTempView('df_mod_movie')\n",
    "\n",
    "spark.sql('SELECT type,added_year,COUNT(*) as count FROM df_mod_movie \\\n",
    "WHERE added_year = 2017 OR added_year = 2018 OR added_year = 2019 OR added_year = 2020 or added_year = 2021 \\\n",
    "GROUP BY type,added_year ORDER BY added_year').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% increase from 2017 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.624129930394425"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#increase from 2017 to 2020\n",
    "((1307/862)-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% drop from 2019 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.633689839572193"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decrease from 2019 to 2020\n",
    "((1307/1496)-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Average Duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|AVG MOVIE DURATION|\n",
      "+------------------+\n",
      "|             99.31|\n",
      "+------------------+\n",
      "\n",
      "+-------------------+\n",
      "|AVG TV SHOW SEASONS|\n",
      "+-------------------+\n",
      "|               1.78|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#average duration of movies and average seasons of tv shows\n",
    "\n",
    "from pyspark.sql.types import IntegerType,ShortType,StringType,StructField\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_mod_movie_duration = df_mod_movie.withColumn('duration_int',(split(df['duration'],' ')[0]).cast('Integer'))\n",
    "df_mod_movie_duration.withColumn('duration_int',when(col('duration_int')>350,0).otherwise(col('duration_int'))) \\\n",
    "                     .orderBy(df_mod_movie_duration['duration_int'].desc())\\\n",
    "                     .select(round(mean('duration_int'),2).alias('AVG MOVIE DURATION')).show()\n",
    "\n",
    "\n",
    "df_mod_tv_show_season = df_mod_tv_show.withColumn('seasons',split('duration',' ')[0].cast('Integer'))\n",
    "df_mod_tv_show_season.select(round(mean('seasons'),2).alias('AVG TV SHOW SEASONS')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Popular Actors and Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|director              |count|\n",
      "+----------------------+-----+\n",
      "|Raúl Campos, Jan Suter|18   |\n",
      "|Marcus Raboy          |15   |\n",
      "|Jay Karas             |14   |\n",
      "|Cathy Garcia-Molina   |13   |\n",
      "|Youssef Chahine       |12   |\n",
      "|Martin Scorsese       |12   |\n",
      "|Jay Chapman           |12   |\n",
      "|Steven Spielberg      |10   |\n",
      "|David Dhawan          |9    |\n",
      "|Kunle Afolayan        |8    |\n",
      "+----------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# popular directors by movies\n",
    "\n",
    "df_mod_movie.groupBy('director').count().\\\n",
    "orderBy(col('count').desc()).filter(col('director')!='null').show(10,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 List of movies by Raul Campos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|title                                      |\n",
      "+-------------------------------------------+\n",
      "|Alan Saldaña: Mi vida de pobre             |\n",
      "|Arango y Sanint: Ríase el show             |\n",
      "|Carlos Ballarta: Furia Ñera                |\n",
      "|Coco y Raulito: Carrusel de ternura        |\n",
      "|Daniel Sosa: Sosafado                      |\n",
      "|Fernando Sanjiao: Hombre                   |\n",
      "|Jani Dueñas: Grandes fracasos de ayer y hoy|\n",
      "|Luciano Mellera: Infantiloide              |\n",
      "|Malena Pichot: Estupidez compleja          |\n",
      "|Mea Culpa                                  |\n",
      "|Natalia Valdebenito: El especial           |\n",
      "|Ricardo O'Farrill Abrazo Genial            |\n",
      "|Ricardo O'Farrill: Abrazo navideño         |\n",
      "|Ricardo Quevedo: Hay gente así             |\n",
      "|Sebastián Marcelo Wainraich                |\n",
      "|Sofía Niño de Rivera: Exposed              |\n",
      "|Sofía Niño de Rivera: Selección Natural    |\n",
      "|Todo lo que sería Lucas Lauriente          |\n",
      "+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# movies by Raúl Campos, Jan Suter\n",
    "number_of_movies = df.filter(col('director')=='Raúl Campos, Jan Suter').select('title').count()\n",
    "\n",
    "df.filter(col('director')=='Raúl Campos, Jan Suter').select('title').show(number_of_movies, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Looking at my personal favourite Martin Scoreses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+\n",
      "|title                                                      |\n",
      "+-----------------------------------------------------------+\n",
      "|Alice Doesn't Live Here Anymore                            |\n",
      "|Gangs of New York                                          |\n",
      "|GoodFellas                                                 |\n",
      "|Hugo                                                       |\n",
      "|Mean Streets                                               |\n",
      "|No Direction Home: Bob Dylan                               |\n",
      "|Raging Bull                                                |\n",
      "|Rolling Thunder Revue: A Bob Dylan Story by Martin Scorsese|\n",
      "|Taxi Driver                                                |\n",
      "|The Departed                                               |\n",
      "|The Irishman                                               |\n",
      "|Who's That Knocking at My Door?                            |\n",
      "+-----------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# movies by Martin Scorsese\n",
    "number_of_movies = df.filter(col('director')=='Martin Scorsese').select('title').count()\n",
    "\n",
    "df.filter(col('director')=='Martin Scorsese').select('title').show(number_of_movies,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Martin Scorsese often works with the same actors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting cast members who have worked with Martin Scorsese\n",
    "martin_cast = []\n",
    "for num in range(1,df.filter(col('director')=='Martin Scorsese').select('cast').count()):\n",
    "    for i in df.filter(col('director')=='Martin Scorsese').withColumn('cast',split('cast',','))\\\n",
    "    .select('cast').collect()[num][0]:\n",
    "        martin_cast.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|        actors|count|\n",
      "+--------------+-----+\n",
      "|Robert De Niro|    5|\n",
      "| Harvey Keitel|    4|\n",
      "|     Joe Pesci|    3|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 3 actors who have worked with Martin\n",
    "spark.createDataFrame(martin_cast,'String')\\\n",
    ".toDF('actors').groupBy('actors').count().orderBy(col('count').desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Honourable mention to Leonardo DiCaprio who is my favourite :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|           actors|count|\n",
      "+-----------------+-----+\n",
      "|Leonardo DiCaprio|    2|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(martin_cast,'String')\\\n",
    ".toDF('actors').groupBy('actors').count().filter(col('actors')=='Leonardo DiCaprio').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Popular TV Show Directors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|director           |count|\n",
      "+-------------------+-----+\n",
      "|Alastair Fothergill|3    |\n",
      "|Shin Won-ho        |2    |\n",
      "|Rob Seidenglanz    |2    |\n",
      "|Stan Lathan        |2    |\n",
      "|Ken Burns          |2    |\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# popular directors by tv shows\n",
    "\n",
    "df_mod_tv_show.groupBy('director').count().\\\n",
    "orderBy(col('count').desc()).filter(col('director')!='null').show(5,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at Alastair Fothergill**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+------------------+\n",
      "|title                                           |cast              |\n",
      "+------------------------------------------------+------------------+\n",
      "|Frozen Planet                                   |David Attenborough|\n",
      "|Planet Earth: The Complete Collection           |David Attenborough|\n",
      "|The Blue Planet: A Natural History of the Oceans|David Attenborough|\n",
      "+------------------------------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tv shows by Alastair Fothergill\n",
    "df.filter(col('director')=='Alastair Fothergill').select('title','cast').show(3,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Popular Movie Actors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting movie actors from cast\n",
    "\n",
    "actor_movie = []\n",
    "\n",
    "df_movie_actor_list = df_mod_movie.na.drop(subset='cast').withColumn('cast_mod',split(col('cast'),',')).select('cast_mod')\n",
    "\n",
    "for num in range(0,df_movie_actor_list.count()):\n",
    "    for i in df_movie_actor_list.collect()[num][0]:\n",
    "        \n",
    "        actor_movie.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|            actor|count|\n",
      "+-----------------+-----+\n",
      "|      Anupam Kher|   37|\n",
      "|          Om Puri|   27|\n",
      "|   Shah Rukh Khan|   27|\n",
      "|      Boman Irani|   25|\n",
      "|     Paresh Rawal|   24|\n",
      "|     Akshay Kumar|   22|\n",
      "|   Kareena Kapoor|   20|\n",
      "|     Adam Sandler|   19|\n",
      "|   Gulshan Grover|   18|\n",
      "|   Yashpal Sharma|   18|\n",
      "| Naseeruddin Shah|   18|\n",
      "| Amitabh Bachchan|   18|\n",
      "|           Asrani|   17|\n",
      "|      John Cleese|   17|\n",
      "|    Andrea Libman|   16|\n",
      "|      Manoj Joshi|   16|\n",
      "|       Ajay Devgn|   16|\n",
      "|      Amrish Puri|   16|\n",
      "|     Hassan Hosny|   16|\n",
      "|       Vijay Raaz|   15|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie_cast = spark.createDataFrame(actor_movie,StringType()).toDF('actor') \n",
    "\n",
    "df_movie_cast.groupBy('actor').count().orderBy(col('count').desc()).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Popular TV Show Actors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting tv show actors from cast\n",
    "\n",
    "df_tv_show_actor_list = df_mod_tv_show.na.drop(subset='cast').withColumn('cast_mod',split('cast',',')).select('cast_mod')\n",
    "\n",
    "actor_tv_show = []\n",
    "\n",
    "for num in range(0,df_tv_show_actor_list.count()):\n",
    "    for i in df_tv_show_actor_list.collect()[num][0]:\n",
    "        actor_tv_show.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|             actor|count|\n",
      "+------------------+-----+\n",
      "|  Takahiro Sakurai|   22|\n",
      "|         Ai Kayano|   16|\n",
      "|    Junichi Suwabe|   15|\n",
      "|         Yuki Kaji|   15|\n",
      "|       Daisuke Ono|   13|\n",
      "|David Attenborough|   13|\n",
      "|     Kana Hanazawa|   12|\n",
      "|   Tomokazu Sugita|   12|\n",
      "|  Yoshimasa Hosoya|   12|\n",
      "|   Yuichi Nakamura|   11|\n",
      "|      Vincent Tong|   11|\n",
      "|    Hiroshi Kamiya|   10|\n",
      "| Katsuyuki Konishi|   10|\n",
      "|  Miyuki Sawashiro|   10|\n",
      "|      Jun Fukuyama|    9|\n",
      "|     Mamoru Miyano|    9|\n",
      "|      Eri Kitamura|    9|\n",
      "|     Kenjiro Tsuda|    9|\n",
      "|  Nobuhiko Okamoto|    9|\n",
      "|     Ashleigh Ball|    9|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tv_show_cast = spark.createDataFrame(actor_tv_show,StringType()).toDF('actor')\n",
    "\n",
    "df_tv_show_cast.groupBy('actor').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Looking at Genres\n",
    "\n",
    "The modern-day consumer is willing to look past subtitles on the screen and discover content which is completely different to their native language making **international movies** a very popular genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting genres from listed_in\n",
    "\n",
    "genre_list = df.withColumn('main_genre',split(col('listed_in'),',')).select('main_genre').na.drop()\n",
    "genres = []\n",
    "for num in range(0,genre_list.count()):\n",
    "    for i in genre_list.collect()[num][0]:\n",
    "        genres.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|genre                |count|\n",
      "+---------------------+-----+\n",
      "| International Movies|2322 |\n",
      "|Dramas               |1380 |\n",
      "|Comedies             |1070 |\n",
      "|Documentaries        |750  |\n",
      "|Action & Adventure   |720  |\n",
      "+---------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# popular genres\n",
    "\n",
    "df_main_genre = spark.createDataFrame(genres,StringType()).toDF('genre')\n",
    "\n",
    "df_main_genre.groupBy('genre').count().orderBy(col('count').desc()).show(5,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aligining values correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|genre               |count|\n",
      "+--------------------+-----+\n",
      "|International Movies|2434 |\n",
      "|Dramas              |2100 |\n",
      "|Comedies            |1467 |\n",
      "|Documentaries       |784  |\n",
      "|Action & Adventure  |720  |\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_main_genre.withColumn('genre',regexp_replace('genre',' Dramas','Dramas')).\\\n",
    "              withColumn('genre',regexp_replace('genre',' Comedies','Comedies')).\\\n",
    "              withColumn('genre',regexp_replace('genre',' Comedies','Comedies')).\\\n",
    "              withColumn('genre',regexp_replace('genre',' International Movies','International Movies')).\\\n",
    "              withColumn('genre',regexp_replace('genre',' Documentaries','Documentaries')).\\\n",
    "              withColumn('genre',regexp_replace('genre',' Action & Adventure','Action & Adventure')).\\\n",
    "              groupBy('genre').count().orderBy(col('count').desc()).show(5,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Looking at Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ('TV-14' ,'TV-PG', 'R' , 'PG-13' , 'TV-Y' , 'TV-Y7' , 'PG' , 'TV-G' , 'NR' , 'G' , 'TV-Y7-FV' , 'UR' , 'NC-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "|rating|count|Share%|\n",
      "+------+-----+------+\n",
      "| TV-14| 1929| 39.28|\n",
      "| TV-PG|  805| 16.39|\n",
      "|     R|  663|  13.5|\n",
      "| PG-13|  386|  7.86|\n",
      "|  TV-Y|  280|   5.7|\n",
      "+------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# popular ratings\n",
    "\n",
    "df_mod_genre = df.filter((col('rating') =='TV-14') | (col('rating') =='TV-PG') | (col('rating') =='R') | \\\n",
    "                         (col('rating') =='PG-13') | (col('rating') == 'TV-Y')  | (col('rating') == 'TV-Y7')  | \\\n",
    "                         (col('rating') =='PG') | (col('rating') =='TV-G') | (col('rating') =='NR') | (col('rating') =='G') |\\\n",
    "                         (col('rating') =='TV-Y7-FV') | (col('rating') =='UR') | (col('rating') =='NC-17')).groupBy('rating').count()\\\n",
    "                 .orderBy(col('count').desc())\n",
    "\n",
    "df_mod_genre.withColumn('Share%',round(col('count')/df_mod_genre.select(sum('count')).collect()[0][0]*100,2)).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Top Countries by TV Show and Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 By TV Show**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting countries from country list for tv show\n",
    "df_mod_country_tv_show = df_mod_tv_show.withColumn('country_mod',split('country',',')).select('country_mod').na.drop()\n",
    "\n",
    "country_list_tv_show = []\n",
    "\n",
    "for num in range(0,df_mod_country_tv_show.count()):\n",
    "    for i in df_mod_country_tv_show.collect()[num][0]:\n",
    "        country_list_tv_show.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------+\n",
      "|country       |count|Share%|\n",
      "+--------------+-----+------+\n",
      "|United States |781  |31.83 |\n",
      "|United Kingdom|236  |9.62  |\n",
      "|Japan         |162  |6.6   |\n",
      "+--------------+-----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# countries with highest tv show content - top 3\n",
    "df_country_tv_show = spark.createDataFrame(country_list_tv_show,StringType()).toDF('country')\n",
    "\n",
    "total_country_tv_show_sum = df_country_tv_show.groupBy('country').count().agg({'count':'sum'}).collect()[0][0]\n",
    "\n",
    "df_country_tv_show.groupBy('country').count().orderBy(col('count').desc()).\\\n",
    "withColumn('Share%',round(col('count')/total_country_tv_show_sum*100,2)).show(3,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formatting country values correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------+\n",
      "|country       |count|Share%|\n",
      "+--------------+-----+------+\n",
      "|United States |864  |35.21 |\n",
      "|United Kingdom|236  |9.62  |\n",
      "|Japan         |162  |6.6   |\n",
      "+--------------+-----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_country_tv_show.withColumn('country',regexp_replace('country',' United States','United States')).\\\n",
    "                   groupBy('country').count().orderBy(col('count').desc()).\\\n",
    "                   withColumn('Share%',round(col('count')/total_country_tv_show_sum*100,2)).show(3,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 By Movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting countries from country list for movies\n",
    "df_mod_country_movie = df_mod_movie.withColumn('country_mod',split('country',',')).select('country_mod').na.drop()\n",
    "\n",
    "country_list_movie = []\n",
    "\n",
    "for num in range(0,df_mod_country_movie.count()):\n",
    "    for i in df_mod_country_movie.collect()[num][0]:\n",
    "        country_list_movie.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------+\n",
      "|country       |count|Share%|\n",
      "+--------------+-----+------+\n",
      "|United States |2090 |31.61 |\n",
      "|India         |883  |13.36 |\n",
      "|United Kingdom|341  |5.16  |\n",
      "+--------------+-----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# countries with highest movie content - top 3\n",
    "df_country_movie = spark.createDataFrame(country_list_movie,StringType()).toDF('country')\n",
    "\n",
    "total_country_movie_sum = df_country_movie.groupBy('country').count().agg({'count':'sum'}).collect()[0][0]\n",
    "\n",
    "df_country_movie.groupBy('country').count().orderBy(col('count').desc())\\\n",
    "                .withColumn('Share%',round(col('count')/total_country_movie_sum*100,2))\\\n",
    "                .withColumn('country',regexp_replace('country',' United States','United States')).show(3,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Looking at United Kingdom and India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas data table for United Kingdom with type and year\n",
    "\n",
    "df_mod_country_total = df_mod.withColumn('country_mod',split('country',','))\\\n",
    "                       .select('title','type','added_year','country_mod')\\\n",
    "                       .na.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_mod_list = []\n",
    "type_mod_list = []\n",
    "country_mod_list = []\n",
    "title_mod_list = []\n",
    "for num in range(1,df_mod_country_total.count()):\n",
    "    for i in df_mod_country_total.collect()[num][3]:\n",
    "        year_mod_list.append(df_mod_country_total.collect()[num][2])\n",
    "        type_mod_list.append(df_mod_country_total.collect()[num][1])\n",
    "        country_mod_list.append(i)\n",
    "        title_mod_list.append(df_mod_country_total.collect()[num][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-------+-----+\n",
      "|       country|Movie|TV Show|Total|\n",
      "+--------------+-----+-------+-----+\n",
      "|United Kingdom|  341|    235|  576|\n",
      "|         India|  883|     73|  956|\n",
      "+--------------+-----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_mod_spark.groupBy('country').pivot('type').count().na.drop().orderBy(col('Movie'))\\\n",
    "                 .filter((col('country')=='United Kingdom')|(col('country')=='India'))\\\n",
    "                 .withColumn('Total',col('Movie')+col('TV Show')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 United Kingdom\n",
    "Looking at United Kingdom Yearly Growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1.1 Total Content Added Yearly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = [year_mod_list,type_mod_list,country_mod_list,title_mod_list]\n",
    "country_year = pd.DataFrame(data).transpose().rename(columns=({2:'country',0:'year',1:'type',3:'title'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mod_spark = spark.createDataFrame(country_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mod_spark = country_mod_spark.select('year','type','country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+\n",
      "|       country| year|count|\n",
      "+--------------+-----+-----+\n",
      "|United Kingdom| 2014|    3|\n",
      "|United Kingdom| 2015|    4|\n",
      "|United Kingdom| 2016|   45|\n",
      "|United Kingdom| 2017|  119|\n",
      "|United Kingdom| 2018|  117|\n",
      "|United Kingdom| 2019|  160|\n",
      "|United Kingdom| 2020|  122|\n",
      "|United Kingdom| 2021|    6|\n",
      "+--------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_mod_spark.groupBy('country','year').count().filter(col('country')=='United Kingdom').orderBy('year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1.2 TV Show Content Added Yearly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+\n",
      "|       country| year|count|\n",
      "+--------------+-----+-----+\n",
      "|United Kingdom| 2015|    3|\n",
      "|United Kingdom| 2016|   20|\n",
      "|United Kingdom| 2017|   49|\n",
      "|United Kingdom| 2018|   42|\n",
      "|United Kingdom| 2019|   61|\n",
      "|United Kingdom| 2020|   58|\n",
      "|United Kingdom| 2021|    2|\n",
      "+--------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tv shows added over the years\n",
    "country_mod_spark.filter(col('country')=='United Kingdom').filter(col('type')=='TV Show')\\\n",
    "                 .groupBy('country','year').count().orderBy('year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1.3 Movie Content Added Yearly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+\n",
      "|       country| year|count|\n",
      "+--------------+-----+-----+\n",
      "|United Kingdom| 2014|    3|\n",
      "|United Kingdom| 2015|    1|\n",
      "|United Kingdom| 2016|   25|\n",
      "|United Kingdom| 2017|   70|\n",
      "|United Kingdom| 2018|   75|\n",
      "|United Kingdom| 2019|   99|\n",
      "|United Kingdom| 2020|   64|\n",
      "|United Kingdom| 2021|    4|\n",
      "+--------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# movies added over the years\n",
    "country_mod_spark.filter(col('country')=='United Kingdom').filter(col('type')=='Movie')\\\n",
    "                 .groupBy('country','year').count().orderBy('year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 India"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2.1 Total Content Added Yearly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|country| year|count|\n",
      "+-------+-----+-----+\n",
      "|  India| 2016|   12|\n",
      "|  India| 2017|  154|\n",
      "|  India| 2018|  346|\n",
      "|  India| 2019|  235|\n",
      "|  India| 2020|  196|\n",
      "|  India| 2021|   13|\n",
      "+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#content added over the years\n",
    "country_mod_spark.groupBy('country','year').count().filter(col('country')=='India').orderBy('year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2.2 TV Show Added Yearly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|country| year|count|\n",
      "+-------+-----+-----+\n",
      "|  India| 2017|   14|\n",
      "|  India| 2018|   20|\n",
      "|  India| 2019|   19|\n",
      "|  India| 2020|   19|\n",
      "|  India| 2021|    1|\n",
      "+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_mod_spark.filter(col('country')=='India').filter(col('type')=='TV Show')\\\n",
    "                 .groupBy('country','year').count().orderBy('year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2.3 Movie Added Yearly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|country| year|count|\n",
      "+-------+-----+-----+\n",
      "|  India| 2016|   12|\n",
      "|  India| 2017|  140|\n",
      "|  India| 2018|  326|\n",
      "|  India| 2019|  216|\n",
      "|  India| 2020|  177|\n",
      "|  India| 2021|   12|\n",
      "+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# movies added over the years\n",
    "country_mod_spark.filter(col('country')=='India').filter(col('type')=='Movie')\\\n",
    "                 .groupBy('country','year').count().orderBy('year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predicting Yearly Content Added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the years from 2016 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_mod.select('added_year').groupBy('added_year').count().orderBy(col('added_year'))\\\n",
    "              .na.drop().filter((col('added_year') > 2015) & (col('added_year') < 2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|added_year|count|\n",
      "+----------+-----+\n",
      "|      2016|  443|\n",
      "|      2017| 1223|\n",
      "|      2018| 1683|\n",
      "|      2019| 2151|\n",
      "|      2020| 2003|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ml.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_ml.withColumn('added_year',col('added_year').cast('Integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['added_year'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(df_ml)\n",
    "final_data = output.select('features','count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining our train and test data set\n",
    "<br>\n",
    "defining our linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])\n",
    "lr = LinearRegression(labelCol='count')\n",
    "lr_model = lr.fit(train_data)\n",
    "test_results = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = test_data.select('features')\n",
    "predictions = lr_model.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting values based on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|features|        prediction|\n",
      "+--------+------------------+\n",
      "|[2020.0]|2771.0000002649613|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|added_year|count|\n",
      "+----------+-----+\n",
      "|      2016|  443|\n",
      "|      2017| 1223|\n",
      "|      2018| 1683|\n",
      "|      2019| 2151|\n",
      "|      2020| 2003|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ml.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% growth from 2019 to 2020 based on predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.82380288238029"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2771/2151-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "projected growth for 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2563.84"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2003*128)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting coefificient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([558.4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coefficients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
